{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import NN\n",
    "import utils\n",
    "from torch import save as save_model\n",
    "from torch import load as load_model\n",
    "import config as cfg\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "warnings.filterwarnings('ignore')\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ETF = 'SPY' # 'SPY', 'DIA', 'QQQ'\n",
    "NNtype = 'MLP' # 'MLP', 'RNN', 'PSN'\n",
    "params = cfg.train_parameters[ETF][NNtype]\n",
    "inputs_lag = cfg.SPYfeatures[NNtype] # SPYfeatures, DIAfeatures, QQQfeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindf = utils.load_file(os.path.join(\"data\", ETF, NNtype, \"Train.pkl\"))\n",
    "validdf = utils.load_file(os.path.join(\"data\", ETF, NNtype, \"Valid.pkl\"))\n",
    "testdf  = utils.load_file(os.path.join(\"data\", ETF, NNtype, \"Test.pkl\"))\n",
    "traindf.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_col = []\n",
    "for i in inputs_lag:\n",
    "    features_col.append(\"Return_\" + str(i))\n",
    "target_col   = 'Target'\n",
    "\n",
    "mu_train, sigma_train = traindf.Return.mean(), traindf.Return.std()\n",
    "mu_val, sigma_val = validdf.Return.mean(), validdf.Return.std()\n",
    "mu_test, sigma_test = testdf.Return.mean(), testdf.Return.std()\n",
    "\n",
    "\n",
    "trainloader = utils.DataFrame2DataLoader(traindf, features_col, target_col, batch_size=1, normalize=True, mu=mu_train, sigma=sigma_train, shuffle=True)\n",
    "validloader = utils.DataFrame2DataLoader(validdf, features_col, target_col, batch_size=1, normalize=True, mu=mu_val, sigma=sigma_val)\n",
    "testloader  = utils.DataFrame2DataLoader(testdf, features_col, target_col, batch_size=1, normalize=True, mu=mu_test, sigma=sigma_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn \n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from utils import mean_absolute_percentage_error, theilU, PT_test\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size=1, hidden_layer_size=70, output_size=1):\n",
    "        super().__init__()\n",
    "        self.hidden_layer_size = hidden_layer_size\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size, hidden_layer_size, num_layers= 2, dropout=0.80)\n",
    "\n",
    "        self.linear = nn.Linear(hidden_layer_size, output_size)\n",
    "\n",
    "        self.hidden_cell = (torch.zeros(2,1,self.hidden_layer_size),\n",
    "                            torch.zeros(2,1,self.hidden_layer_size))\n",
    "\n",
    "    \n",
    "    def forward(self, input_seq):\n",
    "        lstm_out, self.hidden_cell = self.lstm(input_seq.view(len(input_seq) ,1, -1), self.hidden_cell)\n",
    "        predictions = self.linear(lstm_out.view(len(input_seq), -1))\n",
    "        return predictions[-1]\n",
    "    \n",
    "class Model():\n",
    "    def __init__(self, params):\n",
    "        self.model = LSTM()\n",
    "        self.epochs = params[\"epochs\"]\n",
    "        print(self.model.parameters())\n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=params[\"lr\"], weight_decay=0.80)\n",
    "        self.validation = params[\"validation\"]\n",
    "        self.validation_freq = params[\"validation_freq\"]\n",
    "        self.loss_function = nn.MSELoss()\n",
    "        self.scheduler = StepLR(self.optimizer, step_size=2, gamma=0.01)\n",
    "\n",
    "        \n",
    "    def evaluate_model(self, dataloader, mu, sigma):\n",
    "        \n",
    "        valid_preds = []\n",
    "        valid_targets = []\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            loss = 0\n",
    "            for seq, labels in dataloader:\n",
    "                y_pred = self.model(seq.squeeze())\n",
    "                loss += self.loss_function((y_pred + mu) * sigma, (labels + mu) * sigma)\n",
    "                valid_preds.append(y_pred)\n",
    "                valid_targets += labels.numpy().tolist()\n",
    "            \n",
    "        validRMSE = mean_squared_error((valid_targets + mu)* sigma, (valid_preds+mu)*sigma)\n",
    "        validMAE = mean_absolute_error((valid_targets + mu)* sigma, (valid_preds+mu)*sigma)\n",
    "        validMAPE = mean_absolute_percentage_error((np.array(valid_targets)+ mu) * sigma , (np.array(valid_preds) + mu) * sigma)\n",
    "        validTheilU = theilU((np.array(valid_targets)+ mu) * sigma , (np.array(valid_preds) + mu) * sigma)\n",
    "\n",
    "        print(\"MAE : {:.4f} |  MAPE  : {:.4f} |  RMSE : {:.5f} | Theil-U {:.4f}\".format(validMAE, validMAPE, validRMSE, validTheilU))\n",
    "        \n",
    "        plt.plot(valid_preds)\n",
    "        plt.plot(valid_targets)\n",
    "\n",
    "\n",
    "    def train_model(self, trainloader, validloader, mu_train, sigma_train, mu_val, sigma_val): \n",
    "        train_loss = []\n",
    "        val_loss = []\n",
    "        loss_function = nn.MSELoss()\n",
    "        for i in tqdm(range(self.epochs)):\n",
    "            for seq, labels in trainloader:\n",
    "                self.model.train()\n",
    "                self.optimizer.zero_grad()\n",
    "\n",
    "                self.model.hidden_cell = (torch.zeros(2, 1, self.model.hidden_layer_size),\n",
    "                                torch.zeros(2, 1, self.model.hidden_layer_size))\n",
    "\n",
    "                y_pred = self.model(seq.squeeze())\n",
    "\n",
    "                single_loss = self.loss_function(y_pred, labels)\n",
    "                single_loss.item()\n",
    "                single_loss.backward()\n",
    "                self.optimizer.step()\n",
    "                trya += single_loss.item() \n",
    "                self.scheduler.step()\n",
    "\n",
    "            ###############################\n",
    "            ###########Validation##########\n",
    "            ###############################\n",
    "            \n",
    "            if self.validation:\n",
    "                if i%self.validation_freq == 0:\n",
    "                    \n",
    "                    self.model.eval()\n",
    "                    with torch.no_grad():\n",
    "                        loss_valid = 0\n",
    "                        for seq, labels in validloader:\n",
    "                            y_pred = self.model(seq.squeeze())\n",
    "                            loss_valid += self.loss_function((y_pred + mu_val) * sigma_val, (labels + mu_val) * sigma_val)\n",
    "\n",
    "                        val_loss.append(loss_valid.item())\n",
    "                        loss_train = 0 \n",
    "                        for seq, labels in trainloader:\n",
    "                            y_pred = self.model(seq.squeeze())\n",
    "\n",
    "                            loss_train += self.loss_function((y_pred + mu_train) * sigma_train, (labels + mu_train) * sigma_train)\n",
    "                        train_loss.append(loss_train.item())\n",
    "                    print(f'epoch: {i:3} train_loss: {loss_train:10.10f} val_loss: {loss_valid:10.10f} ')\n",
    "        sns.lineplot(list(range(int(self.epochs/self.validation_freq))), train_loss)\n",
    "        sns.lineplot(list(range(int(self.epochs/self.validation_freq))), val_loss)\n",
    "                    \n",
    "    def predict(self, testloader, mu, sigma):\n",
    "        predicted_labels = []\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            for seq, target in testloader:\n",
    "                predicted_labels.append(self.model(seq.squeeze()))\n",
    "        return (predicted_labels + mu) * sigma\n",
    "\n",
    "      \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\"lr\": 0.1, \"epochs\": 15, \"validation\":True, \"validation_freq\":5}\n",
    "\n",
    "print(\"Testing the model with random initialization on the test set.. \")\n",
    "model = Model(params)\n",
    "model.evaluate_model(testloader, mu_test, sigma_test)\n",
    "print(\"Model is training ..\")\n",
    "model.train_model(trainloader, validloader, mu_train, sigma_train, mu_val, sigma_val)\n",
    "print(\"Testing the model after training.. \")\n",
    "model.evaluate_model(testloader, mu_test, sigma_test)\n",
    "\n",
    "preditions = model.predict(testloader, mu_test, sigma_test)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
